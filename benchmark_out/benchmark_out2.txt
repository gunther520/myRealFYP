
python3 benchmarks/benchmark_serving.py         
    --model meta-llama/Llama-3.1-8B-Instruct     
    --dataset-name hf  
    --dataset-path /home/hkngae/test/temp_dataset/output.json     
    --hf-split train   
    --num-prompts {2**i * 10} 
    >> benchmark_out2.txt

Namespace(backend='vllm', base_url=None, host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='hf', dataset_path='/home/hkngae/test/temp_dataset/output.json', max_concurrency=None, model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=20, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, random_prefix_len=0, hf_subset=None, hf_split='train', hf_output_len=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: None
============ Serving Benchmark Result ============
Successful requests:                     20        
Benchmark duration (s):                  18.62     
Total input tokens:                      856       
Total generated tokens:                  11932     
Request throughput (req/s):              1.07      
Output token throughput (tok/s):         640.95    
Total Token throughput (tok/s):          686.93    
---------------Time to First Token----------------
Mean TTFT (ms):                          361.97    
Median TTFT (ms):                        311.17    
P99 TTFT (ms):                           433.58    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          21.24     
Median TPOT (ms):                        21.59     
P99 TPOT (ms):                           24.54     
---------------Inter-token Latency----------------
Mean ITL (ms):                           20.48     
Median ITL (ms):                         20.52     
P99 ITL (ms):                            26.55     
==================================================




Namespace(backend='vllm', base_url=None, host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='hf', dataset_path='/home/hkngae/test/temp_dataset/output.json', max_concurrency=None, model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, random_prefix_len=0, hf_subset=None, hf_split='train', hf_output_len=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: None
============ Serving Benchmark Result ============
Successful requests:                     40        
Benchmark duration (s):                  23.96     
Total input tokens:                      1584      
Total generated tokens:                  21954     
Request throughput (req/s):              1.67      
Output token throughput (tok/s):         916.10    
Total Token throughput (tok/s):          982.20    
---------------Time to First Token----------------
Mean TTFT (ms):                          575.34    
Median TTFT (ms):                        571.28    
P99 TTFT (ms):                           804.20    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          28.42     
Median TPOT (ms):                        28.49     
P99 TPOT (ms):                           33.91     
---------------Inter-token Latency----------------
Mean ITL (ms):                           26.96     
Median ITL (ms):                         27.05     
P99 ITL (ms):                            36.52     
==================================================




Namespace(backend='vllm', base_url=None, host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='hf', dataset_path='/home/hkngae/test/temp_dataset/output.json', max_concurrency=None, model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=80, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, random_prefix_len=0, hf_subset=None, hf_split='train', hf_output_len=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: None
============ Serving Benchmark Result ============
Successful requests:                     80        
Benchmark duration (s):                  36.40     
Total input tokens:                      3396      
Total generated tokens:                  44982     
Request throughput (req/s):              2.20      
Output token throughput (tok/s):         1235.71   
Total Token throughput (tok/s):          1329.00   
---------------Time to First Token----------------
Mean TTFT (ms):                          1581.73   
Median TTFT (ms):                        1615.28   
P99 TTFT (ms):                           2275.54   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          43.94     
Median TPOT (ms):                        43.71     
P99 TPOT (ms):                           56.90     
---------------Inter-token Latency----------------
Mean ITL (ms):                           41.13     
Median ITL (ms):                         41.82     
P99 ITL (ms):                            55.80     
==================================================




Namespace(backend='vllm', base_url=None, host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='hf', dataset_path='/home/hkngae/test/temp_dataset/output.json', max_concurrency=None, model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=160, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, random_prefix_len=0, hf_subset=None, hf_split='train', hf_output_len=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: None
============ Serving Benchmark Result ============
Successful requests:                     160       
Benchmark duration (s):                  56.80     
Total input tokens:                      6460      
Total generated tokens:                  85609     
Request throughput (req/s):              2.82      
Output token throughput (tok/s):         1507.24   
Total Token throughput (tok/s):          1620.97   
---------------Time to First Token----------------
Mean TTFT (ms):                          2228.93   
Median TTFT (ms):                        2172.36   
P99 TTFT (ms):                           3623.65   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          73.77     
Median TPOT (ms):                        71.50     
P99 TPOT (ms):                           111.54    
---------------Inter-token Latency----------------
Mean ITL (ms):                           66.85     
Median ITL (ms):                         64.84     
P99 ITL (ms):                            222.21    
==================================================




Namespace(backend='vllm', base_url=None, host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='hf', dataset_path='/home/hkngae/test/temp_dataset/output.json', max_concurrency=None, model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=320, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, random_prefix_len=0, hf_subset=None, hf_split='train', hf_output_len=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: None
============ Serving Benchmark Result ============
Successful requests:                     320       
Benchmark duration (s):                  97.65     
Total input tokens:                      9998      
Total generated tokens:                  162993    
Request throughput (req/s):              3.28      
Output token throughput (tok/s):         1669.09   
Total Token throughput (tok/s):          1771.47   
---------------Time to First Token----------------
Mean TTFT (ms):                          6503.19   
Median TTFT (ms):                        3057.16   
P99 TTFT (ms):                           33499.56  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          120.40    
Median TPOT (ms):                        122.41    
P99 TPOT (ms):                           159.78    
---------------Inter-token Latency----------------
Mean ITL (ms):                           110.93    
Median ITL (ms):                         109.77    
P99 ITL (ms):                            392.97    
==================================================




Namespace(backend='vllm', base_url=None, host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='hf', dataset_path='/home/hkngae/test/temp_dataset/output.json', max_concurrency=None, model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=640, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, random_prefix_len=0, hf_subset=None, hf_split='train', hf_output_len=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: None
============ Serving Benchmark Result ============
Successful requests:                     640       
Benchmark duration (s):                  188.16    
Total input tokens:                      29832     
Total generated tokens:                  315354    
Request throughput (req/s):              3.40      
Output token throughput (tok/s):         1676.03   
Total Token throughput (tok/s):          1834.58   
---------------Time to First Token----------------
Mean TTFT (ms):                          49938.51  
Median TTFT (ms):                        35799.17  
P99 TTFT (ms):                           134188.40 
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          132.70    
Median TPOT (ms):                        142.44    
P99 TPOT (ms):                           153.13    
---------------Inter-token Latency----------------
Mean ITL (ms):                           128.69    
Median ITL (ms):                         129.82    
P99 ITL (ms):                            423.38    
==================================================




Namespace(backend='vllm', base_url=None, host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='hf', dataset_path='/home/hkngae/test/temp_dataset/output.json', max_concurrency=None, model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=1280, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, random_prefix_len=0, hf_subset=None, hf_split='train', hf_output_len=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: None
============ Serving Benchmark Result ============
Successful requests:                     1198      
Benchmark duration (s):                  586.48    
Total input tokens:                      63283     
Total generated tokens:                  590047    
Request throughput (req/s):              2.04      
Output token throughput (tok/s):         1006.09   
Total Token throughput (tok/s):          1113.99   
---------------Time to First Token----------------
Mean TTFT (ms):                          129154.30 
Median TTFT (ms):                        130349.91 
P99 TTFT (ms):                           291295.96 
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          194.49    
Median TPOT (ms):                        145.97    
P99 TPOT (ms):                           780.83    
---------------Inter-token Latency----------------
Mean ITL (ms):                           207.31    
Median ITL (ms):                         132.62    
P99 ITL (ms):                            495.47    
==================================================




