INFO 01-18 17:02:12 api_server.py:528] vLLM API server version dev
INFO 01-18 17:02:12 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7f9f8c92d000>)
INFO 01-18 17:02:12 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/0c8b11dc-785c-43b0-bd02-64d4d588ea34 for IPC Path.
INFO 01-18 17:02:12 api_server.py:179] Started engine process with PID 1696912
INFO 01-18 17:02:32 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:02:32 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:02:32 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:02:34 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:02:34 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:02:34 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:02:34 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 17:02:35 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 17:02:36 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:02:39 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:02:39 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:02:40 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:02:40 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 17:02:40 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:02:40 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:02:40 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:02:40 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:02:40 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 01-18 17:02:40 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:02:40 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1697245)[0;0m WARNING 01-18 17:02:41 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1697244)[0;0m WARNING 01-18 17:02:41 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1697246)[0;0m WARNING 01-18 17:02:41 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 17:02:41 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 17:02:41 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7fa167353490>, local_subscribe_port=59411, remote_subscribe_port=None)
INFO 01-18 17:02:41 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:02:41 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:02:41 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:02:41 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:02:41 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 17:02:41 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:02:41 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:02:41 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:02:44 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:02:44 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:02:45 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:02:45 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:02:46 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 17:02:46 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:02:48 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:02:48 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:02:48 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:02:48 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 17:02:48 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 17:02:48 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:02:48 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:02:48 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1697244)[0;0m INFO 01-18 17:03:05 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1697246)[0;0m INFO 01-18 17:03:05 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1697245)[0;0m INFO 01-18 17:03:05 model_runner.py:1530] Graph capturing finished in 16 secs.
INFO 01-18 17:03:05 model_runner.py:1530] Graph capturing finished in 16 secs.
INFO 01-18 17:03:05 api_server.py:232] vLLM to use /tmp/tmpphseoc8i as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 17:03:05 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 17:03:05 launcher.py:19] Available routes are:
INFO 01-18 17:03:05 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET
INFO 01-18 17:03:05 launcher.py:27] Route: /docs, Methods: HEAD, GET
INFO 01-18 17:03:05 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 01-18 17:03:05 launcher.py:27] Route: /redoc, Methods: HEAD, GET
INFO 01-18 17:03:05 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 17:03:05 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 17:03:05 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 17:03:05 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 17:03:05 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 17:03:05 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 17:03:05 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 17:03:05 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:47732 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:47744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:03:14 metrics.py:345] Avg prompt throughput: 8.1 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:03:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 104.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60964 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32794 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32810 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32826 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32836 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32838 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32854 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32868 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32890 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:03:24 metrics.py:345] Avg prompt throughput: 171.1 tokens/s, Avg generation throughput: 318.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 01-18 17:03:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 940.5 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO 01-18 17:03:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 684.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:03:41 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 17:03:41 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 17:04:57 api_server.py:528] vLLM API server version dev
INFO 01-18 17:04:57 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7faac5c65090>)
INFO 01-18 17:04:57 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/941c7d4d-ba7c-4e1b-845d-3aab17aed87c for IPC Path.
INFO 01-18 17:04:57 api_server.py:179] Started engine process with PID 1698297
INFO 01-18 17:05:16 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:05:16 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:05:16 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:05:19 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:05:19 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:05:19 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:05:19 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 17:05:20 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 17:05:20 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:24 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:24 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:24 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 17:05:24 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 17:05:24 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:24 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:24 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:24 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:24 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:24 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:24 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1698635)[0;0m WARNING 01-18 17:05:25 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1698637)[0;0m WARNING 01-18 17:05:25 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1698636)[0;0m WARNING 01-18 17:05:25 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 17:05:25 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 17:05:25 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f46eb081000>, local_subscribe_port=47585, remote_subscribe_port=None)
INFO 01-18 17:05:25 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:25 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:25 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:25 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:26 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 17:05:26 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:26 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:26 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:28 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:05:28 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:29 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:29 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:05:30 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 17:05:30 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
INFO 01-18 17:05:33 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 17:05:33 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:33 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:33 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:33 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:33 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:33 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:33 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 17:05:49 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1698635)[0;0m INFO 01-18 17:05:49 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1698636)[0;0m INFO 01-18 17:05:49 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1698637)[0;0m INFO 01-18 17:05:49 model_runner.py:1530] Graph capturing finished in 16 secs.
INFO 01-18 17:05:50 api_server.py:232] vLLM to use /tmp/tmplu4upd9l as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 17:05:50 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 17:05:50 launcher.py:19] Available routes are:
INFO 01-18 17:05:50 launcher.py:27] Route: /openapi.json, Methods: GET, HEAD
INFO 01-18 17:05:50 launcher.py:27] Route: /docs, Methods: GET, HEAD
INFO 01-18 17:05:50 launcher.py:27] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 01-18 17:05:50 launcher.py:27] Route: /redoc, Methods: GET, HEAD
INFO 01-18 17:05:50 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 17:05:50 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 17:05:50 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 17:05:50 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 17:05:50 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 17:05:50 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 17:05:50 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 17:05:50 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:34986 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:34988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:05:59 metrics.py:345] Avg prompt throughput: 7.9 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:06:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 101.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:40706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40714 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40738 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40766 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40788 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40792 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40806 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40812 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40836 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40854 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40868 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40918 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40920 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40924 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40940 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40964 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40982 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41016 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:06:09 metrics.py:345] Avg prompt throughput: 316.2 tokens/s, Avg generation throughput: 319.4 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:06:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1475.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.
INFO 01-18 17:06:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1213.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.
INFO 01-18 17:06:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 914.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:06:29 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 17:06:29 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 17:07:45 api_server.py:528] vLLM API server version dev
INFO 01-18 17:07:45 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7fdf07ba1090>)
INFO 01-18 17:07:45 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/80c0892a-1147-419c-a1ae-573563280dcd for IPC Path.
INFO 01-18 17:07:46 api_server.py:179] Started engine process with PID 1699685
INFO 01-18 17:08:05 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:08:05 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:08:05 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:08:07 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:08:07 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:08:07 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:08:07 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 17:08:09 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 17:08:09 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:12 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:12 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:13 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 17:08:13 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 17:08:13 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:13 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:13 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:13 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:13 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:13 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:13 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1700025)[0;0m WARNING 01-18 17:08:14 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1700024)[0;0m WARNING 01-18 17:08:14 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1700026)[0;0m WARNING 01-18 17:08:14 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 17:08:14 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 17:08:14 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7fc48af13490>, local_subscribe_port=48041, remote_subscribe_port=None)
INFO 01-18 17:08:14 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:14 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:14 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:14 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 01-18 17:08:14 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:14 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:14 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:14 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 17:08:17 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:17 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:18 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:18 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:08:19 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 17:08:19 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:22 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:22 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 17:08:22 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 17:08:22 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:22 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:22 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:22 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:22 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1700024)[0;0m INFO 01-18 17:08:39 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1700025)[0;0m INFO 01-18 17:08:39 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 17:08:39 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1700026)[0;0m INFO 01-18 17:08:39 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 17:08:40 api_server.py:232] vLLM to use /tmp/tmpcbgc4p_3 as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 17:08:40 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 17:08:40 launcher.py:19] Available routes are:
INFO 01-18 17:08:40 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET
INFO 01-18 17:08:40 launcher.py:27] Route: /docs, Methods: HEAD, GET
INFO 01-18 17:08:40 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 01-18 17:08:40 launcher.py:27] Route: /redoc, Methods: HEAD, GET
INFO 01-18 17:08:40 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 17:08:40 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 17:08:40 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 17:08:40 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 17:08:40 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 17:08:40 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 17:08:40 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 17:08:40 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:56838 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:50098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:08:49 metrics.py:345] Avg prompt throughput: 7.4 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:08:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 104.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:38504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38534 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38562 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38578 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38600 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38616 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38658 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38668 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38696 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38708 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38718 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38734 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38812 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38816 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38838 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38852 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38864 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38870 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38918 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38964 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:08:59 metrics.py:345] Avg prompt throughput: 677.6 tokens/s, Avg generation throughput: 225.7 tokens/s, Running: 80 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 01-18 17:09:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1798.3 tokens/s, Running: 71 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.
INFO 01-18 17:09:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1729.3 tokens/s, Running: 66 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.
INFO 01-18 17:09:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1795.0 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.
INFO 01-18 17:09:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1617.4 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.
INFO 01-18 17:09:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1250.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:09:30 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 17:09:30 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 17:10:45 api_server.py:528] vLLM API server version dev
INFO 01-18 17:10:45 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7fae37c29000>)
INFO 01-18 17:10:45 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/6ac1ac1c-f924-404b-af1b-2b5d67f5cbba for IPC Path.
INFO 01-18 17:10:45 api_server.py:179] Started engine process with PID 1701212
INFO 01-18 17:11:05 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:11:05 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:11:05 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:11:08 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:11:08 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:11:08 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:11:08 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 17:11:09 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 17:11:09 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:13 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:13 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:13 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 17:11:13 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:13 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 17:11:13 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:13 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:13 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:13 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:13 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:13 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1702142)[0;0m WARNING 01-18 17:11:14 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1702144)[0;0m WARNING 01-18 17:11:14 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1702143)[0;0m WARNING 01-18 17:11:14 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 17:11:14 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 17:11:14 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f4fda697eb0>, local_subscribe_port=39713, remote_subscribe_port=None)
INFO 01-18 17:11:14 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:14 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:14 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:14 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:15 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:15 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 17:11:15 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:15 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:17 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:18 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:11:19 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:19 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:11:20 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 17:11:20 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:22 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:22 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 17:11:22 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 17:11:22 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:22 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:22 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:22 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:22 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 17:11:39 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1702142)[0;0m INFO 01-18 17:11:39 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1702144)[0;0m INFO 01-18 17:11:39 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1702143)[0;0m INFO 01-18 17:11:39 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 17:11:40 api_server.py:232] vLLM to use /tmp/tmp6six_nzw as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 17:11:40 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 17:11:40 launcher.py:19] Available routes are:
INFO 01-18 17:11:40 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET
INFO 01-18 17:11:40 launcher.py:27] Route: /docs, Methods: HEAD, GET
INFO 01-18 17:11:40 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 01-18 17:11:40 launcher.py:27] Route: /redoc, Methods: HEAD, GET
INFO 01-18 17:11:40 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 17:11:40 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 17:11:40 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 17:11:40 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 17:11:40 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 17:11:40 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 17:11:40 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 17:11:40 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:44148 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:37752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:11:50 metrics.py:345] Avg prompt throughput: 7.4 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:11:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 105.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:53168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53198 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53206 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53268 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53406 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53428 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53462 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53522 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53534 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53542 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53570 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53586 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53606 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53636 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53668 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53686 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53692 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53708 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53730 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53780 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53786 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53796 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53812 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53822 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53836 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53878 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53890 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53920 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53940 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53962 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54120 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:12:00 metrics.py:345] Avg prompt throughput: 823.4 tokens/s, Avg generation throughput: 175.3 tokens/s, Running: 110 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54314 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54366 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54374 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54398 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54410 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54432 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54450 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54452 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54464 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54480 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54500 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54508 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54514 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54544 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:12:05 metrics.py:345] Avg prompt throughput: 456.1 tokens/s, Avg generation throughput: 1897.1 tokens/s, Running: 156 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.
INFO 01-18 17:12:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2165.8 tokens/s, Running: 141 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.
INFO 01-18 17:12:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2071.9 tokens/s, Running: 133 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:12:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2053.4 tokens/s, Running: 118 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.
INFO 01-18 17:12:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2141.2 tokens/s, Running: 103 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.
INFO 01-18 17:12:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2040.7 tokens/s, Running: 92 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:12:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1843.5 tokens/s, Running: 69 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.
INFO 01-18 17:12:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1719.9 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:12:47 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 17:12:47 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 17:14:03 api_server.py:528] vLLM API server version dev
INFO 01-18 17:14:03 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7f75a8e79090>)
INFO 01-18 17:14:03 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/df0acc78-b42c-4d96-bff3-6ce9079ae901 for IPC Path.
INFO 01-18 17:14:03 api_server.py:179] Started engine process with PID 1703569
INFO 01-18 17:14:23 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:14:23 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:14:23 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:14:25 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:14:25 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:14:25 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:14:25 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 17:14:26 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 17:14:26 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:30 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:30 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:30 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 17:14:30 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:30 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:30 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:30 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:30 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:30 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:30 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 01-18 17:14:30 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1703903)[0;0m WARNING 01-18 17:14:31 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1703901)[0;0m WARNING 01-18 17:14:31 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1703902)[0;0m WARNING 01-18 17:14:31 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 17:14:31 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 17:14:31 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f4e3f78beb0>, local_subscribe_port=53131, remote_subscribe_port=None)
INFO 01-18 17:14:31 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:31 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:31 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:31 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 01-18 17:14:32 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:32 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:32 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:32 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 17:14:34 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:35 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:35 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:36 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:14:37 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 17:14:37 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:39 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:39 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 17:14:39 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 17:14:39 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:39 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:39 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:39 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:39 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1703903)[0;0m INFO 01-18 17:14:56 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1703901)[0;0m INFO 01-18 17:14:56 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 17:14:56 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1703902)[0;0m INFO 01-18 17:14:56 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 17:14:57 api_server.py:232] vLLM to use /tmp/tmp0hfdeiaq as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 17:14:57 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 17:14:57 launcher.py:19] Available routes are:
INFO 01-18 17:14:57 launcher.py:27] Route: /openapi.json, Methods: GET, HEAD
INFO 01-18 17:14:57 launcher.py:27] Route: /docs, Methods: GET, HEAD
INFO 01-18 17:14:57 launcher.py:27] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 01-18 17:14:57 launcher.py:27] Route: /redoc, Methods: GET, HEAD
INFO 01-18 17:14:57 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 17:14:57 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 17:14:57 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 17:14:57 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 17:14:57 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 17:14:57 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 17:14:57 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 17:14:57 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:54368 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:54380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:15:05 metrics.py:345] Avg prompt throughput: 8.8 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:15:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 103.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:50034 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50198 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50348 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50378 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50416 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50436 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50442 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50468 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50508 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50522 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50548 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50562 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50578 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50582 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50598 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50650 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50700 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50708 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50718 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50720 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50780 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50796 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50810 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50890 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50924 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51038 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:15:15 metrics.py:345] Avg prompt throughput: 781.5 tokens/s, Avg generation throughput: 168.9 tokens/s, Running: 106 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:51068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51112 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51340 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51408 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51420 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51440 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51444 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51456 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51464 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51484 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51506 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51562 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51578 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51586 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51588 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51606 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51640 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51654 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51664 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40804 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40816 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40830 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40870 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40892 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40924 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41206 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41354 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41368 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41392 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41420 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41432 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41436 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41440 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41450 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41452 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41528 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41542 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41544 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41564 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41580 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41588 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41612 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41638 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41640 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41646 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41668 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41694 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41708 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41734 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41750 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41788 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41892 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41894 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 17:15:20 metrics.py:345] Avg prompt throughput: 699.3 tokens/s, Avg generation throughput: 1809.9 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 62 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:15:25 metrics.py:345] Avg prompt throughput: 23.0 tokens/s, Avg generation throughput: 2213.3 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 51 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:15:30 metrics.py:345] Avg prompt throughput: 35.5 tokens/s, Avg generation throughput: 2304.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 33 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.
INFO 01-18 17:15:35 metrics.py:345] Avg prompt throughput: 149.1 tokens/s, Avg generation throughput: 2217.3 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 15 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
INFO 01-18 17:15:41 metrics.py:345] Avg prompt throughput: 219.5 tokens/s, Avg generation throughput: 2221.4 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:15:46 metrics.py:345] Avg prompt throughput: 52.5 tokens/s, Avg generation throughput: 2330.9 tokens/s, Running: 245 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:15:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2196.3 tokens/s, Running: 230 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.
INFO 01-18 17:15:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2286.3 tokens/s, Running: 211 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 01-18 17:16:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2220.5 tokens/s, Running: 197 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:16:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2207.7 tokens/s, Running: 182 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.
INFO 01-18 17:16:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2162.3 tokens/s, Running: 163 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.
INFO 01-18 17:16:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2058.7 tokens/s, Running: 142 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.
INFO 01-18 17:16:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1880.7 tokens/s, Running: 112 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO 01-18 17:16:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1954.9 tokens/s, Running: 81 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 01-18 17:16:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1615.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.9%, CPU KV cache usage: 0.0%.
INFO 01-18 17:16:37 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 17:16:37 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 17:17:54 api_server.py:528] vLLM API server version dev
INFO 01-18 17:17:54 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7f8ee0a59090>)
INFO 01-18 17:17:54 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/3ddb65d6-7d32-468f-bd57-47cb9450a994 for IPC Path.
INFO 01-18 17:17:54 api_server.py:179] Started engine process with PID 1705515
INFO 01-18 17:18:13 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:18:13 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:18:13 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:18:16 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 17:18:16 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 17:18:16 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 17:18:16 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 17:18:16 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 17:18:16 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1705858)[0;0m INFO 01-18 17:18:20 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1705859)[0;0m INFO 01-18 17:18:20 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1705860)[0;0m INFO 01-18 17:18:20 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 17:18:21 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1705858)[0;0m INFO 01-18 17:18:21 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1705858)[0;0m INFO 01-18 17:18:21 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 01-18 17:18:21 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1705860)[0;0m INFO 01-18 17:18:21 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1705860)[0;0m INFO 01-18 17:18:21 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1705859)[0;0m INFO 01-18 17:18:21 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1705859)[0;0m INFO 01-18 17:18:21 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1705858)[0;0m WARNING 01-18 17:18:22 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 17:18:22 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1705859)[0;0m WARNING 01-18 17:18:22 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1705860)[0;0m WARNING 01-18 17:18:22 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 17:18:22 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f73b966e980>, local_subscribe_port=55779, remote_subscribe_port=None)
INFO 01-18 17:18:22 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1705860)[0;0m INFO 01-18 17:18:22 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1705859)[0;0m INFO 01-18 17:18:22 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1705858)[0;0m INFO 01-18 17:18:22 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 01-18 17:18:22 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1705860)[0;0m INFO 01-18 17:18:22 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1705859)[0;0m INFO 01-18 17:18:22 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1705858)[0;0m INFO 01-18 17:18:23 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 17:18:25 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1705860)[0;0m INFO 01-18 17:18:25 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1705858)[0;0m INFO 01-18 17:18:26 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1705859)[0;0m INFO 01-18 17:18:26 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 17:18:27 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 17:18:27 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
INFO 01-18 17:18:29 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 17:18:29 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1705859)[0;0m INFO 01-18 17:18:30 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1705859)[0;0m INFO 01-18 17:18:30 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1705858)[0;0m INFO 01-18 17:18:30 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1705858)[0;0m INFO 01-18 17:18:30 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1705860)[0;0m INFO 01-18 17:18:30 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1705860)[0;0m INFO 01-18 17:18:30 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
ERROR 01-18 17:18:46 multiproc_worker_utils.py:117] Worker VllmWorkerProcess pid 1705858 died, exit code: -15
INFO 01-18 17:18:46 multiproc_worker_utils.py:121] Killing local vLLM worker processes
INFO 01-18 18:12:08 api_server.py:528] vLLM API server version dev
INFO 01-18 18:12:08 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7f49bb0bd000>)
INFO 01-18 18:12:08 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/999c873c-23d9-4d9b-9593-0049d539afbe for IPC Path.
INFO 01-18 18:12:08 api_server.py:179] Started engine process with PID 1711446
INFO 01-18 18:12:14 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:12:14 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:12:14 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:12:17 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:12:17 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:12:17 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:12:17 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 18:12:19 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 18:12:19 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:23 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:23 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:23 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 18:12:24 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:24 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:24 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 18:12:24 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:24 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:24 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:24 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:24 pynccl.py:63] vLLM is using nccl==2.20.5
WARNING 01-18 18:12:25 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1711743)[0;0m WARNING 01-18 18:12:25 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1711742)[0;0m WARNING 01-18 18:12:25 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1711741)[0;0m WARNING 01-18 18:12:25 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 18:12:25 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7fe22b781a20>, local_subscribe_port=52065, remote_subscribe_port=None)
INFO 01-18 18:12:25 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:25 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:25 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:25 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:25 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 18:12:25 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:25 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:25 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:28 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:28 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:29 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:12:29 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:12:30 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 18:12:30 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:32 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:32 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:32 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 18:12:32 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:32 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 18:12:32 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:33 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:33 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1711743)[0;0m INFO 01-18 18:12:50 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 18:12:50 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1711741)[0;0m INFO 01-18 18:12:50 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1711742)[0;0m INFO 01-18 18:12:50 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 18:12:50 api_server.py:232] vLLM to use /tmp/tmp4kbb1htd as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 18:12:50 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 18:12:50 launcher.py:19] Available routes are:
INFO 01-18 18:12:50 launcher.py:27] Route: /openapi.json, Methods: GET, HEAD
INFO 01-18 18:12:50 launcher.py:27] Route: /docs, Methods: GET, HEAD
INFO 01-18 18:12:50 launcher.py:27] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 01-18 18:12:50 launcher.py:27] Route: /redoc, Methods: GET, HEAD
INFO 01-18 18:12:50 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 18:12:50 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 18:12:50 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 18:12:50 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 18:12:50 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 18:12:50 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 18:12:50 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 18:12:50 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:55868 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:55882 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:12:59 metrics.py:345] Avg prompt throughput: 8.7 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:13:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 104.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:45430 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45462 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45480 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45484 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45514 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45544 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45562 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45574 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45590 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:13:09 metrics.py:345] Avg prompt throughput: 170.7 tokens/s, Avg generation throughput: 321.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:13:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 954.6 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:13:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 683.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:13:25 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 18:13:25 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 18:14:41 api_server.py:528] vLLM API server version dev
INFO 01-18 18:14:41 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7fd456c41000>)
INFO 01-18 18:14:41 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/7bf7c551-eb23-4a11-8a96-5234a644d6e2 for IPC Path.
INFO 01-18 18:14:41 api_server.py:179] Started engine process with PID 1712849
INFO 01-18 18:15:00 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:15:00 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:15:00 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:15:02 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:15:02 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:15:02 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:15:02 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 18:15:03 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 18:15:03 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:07 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:07 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:07 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 18:15:08 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:08 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 18:15:08 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:08 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:08 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:08 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:08 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:08 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1713184)[0;0m WARNING 01-18 18:15:08 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1713185)[0;0m WARNING 01-18 18:15:08 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1713186)[0;0m WARNING 01-18 18:15:08 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 18:15:08 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 18:15:08 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f022d62e2c0>, local_subscribe_port=57979, remote_subscribe_port=None)
INFO 01-18 18:15:08 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:08 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:08 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:08 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 01-18 18:15:09 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:09 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:09 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:09 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 18:15:11 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:12 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:12 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:13 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:15:14 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 18:15:14 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
INFO 01-18 18:15:16 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 18:15:16 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:16 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:16 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:16 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:16 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:16 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:16 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 18:15:33 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1713185)[0;0m INFO 01-18 18:15:33 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1713184)[0;0m INFO 01-18 18:15:33 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1713186)[0;0m INFO 01-18 18:15:33 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 18:15:34 api_server.py:232] vLLM to use /tmp/tmpmxgljhzu as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 18:15:34 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 18:15:34 launcher.py:19] Available routes are:
INFO 01-18 18:15:34 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET
INFO 01-18 18:15:34 launcher.py:27] Route: /docs, Methods: HEAD, GET
INFO 01-18 18:15:34 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 01-18 18:15:34 launcher.py:27] Route: /redoc, Methods: HEAD, GET
INFO 01-18 18:15:34 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 18:15:34 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 18:15:34 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 18:15:34 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 18:15:34 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 18:15:34 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 18:15:34 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 18:15:34 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:48314 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:33858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:15:43 metrics.py:345] Avg prompt throughput: 7.9 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:15:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 104.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:51640 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51670 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51686 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51700 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51704 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51714 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51734 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51750 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51766 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51788 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51800 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51806 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51812 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51828 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51844 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51870 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51890 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51918 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:15:53 metrics.py:345] Avg prompt throughput: 316.0 tokens/s, Avg generation throughput: 394.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:15:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1470.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:16:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1172.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:16:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 848.5 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:16:13 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 18:16:13 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 18:17:29 api_server.py:528] vLLM API server version dev
INFO 01-18 18:17:29 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7fbd22b49000>)
INFO 01-18 18:17:29 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/baf66caa-f71d-4cc9-97a8-7eace479d4b3 for IPC Path.
INFO 01-18 18:17:29 api_server.py:179] Started engine process with PID 1714273
INFO 01-18 18:17:47 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:17:47 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:17:47 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:17:50 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:17:50 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:17:50 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:17:50 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 18:17:51 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 18:17:51 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:17:55 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:17:55 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:17:55 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 18:17:55 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:17:55 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 18:17:55 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:17:55 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:17:55 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:17:55 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:17:55 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:17:55 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1714602)[0;0m WARNING 01-18 18:17:56 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1714604)[0;0m WARNING 01-18 18:17:56 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 18:17:56 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1714603)[0;0m WARNING 01-18 18:17:56 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 18:17:56 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f7c5c045a20>, local_subscribe_port=49217, remote_subscribe_port=None)
INFO 01-18 18:17:56 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:17:56 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:17:56 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:17:56 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:17:56 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 18:17:56 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:17:56 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:17:56 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:17:59 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:17:59 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:18:00 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:18:00 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:18:01 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 18:18:01 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:18:04 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:18:04 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 18:18:04 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 18:18:04 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:18:04 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:18:04 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:18:04 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:18:04 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1714603)[0;0m INFO 01-18 18:18:21 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1714604)[0;0m INFO 01-18 18:18:21 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1714602)[0;0m INFO 01-18 18:18:21 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 18:18:21 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 18:18:22 api_server.py:232] vLLM to use /tmp/tmpkijn28qr as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 18:18:22 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 18:18:22 launcher.py:19] Available routes are:
INFO 01-18 18:18:22 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET
INFO 01-18 18:18:22 launcher.py:27] Route: /docs, Methods: HEAD, GET
INFO 01-18 18:18:22 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 01-18 18:18:22 launcher.py:27] Route: /redoc, Methods: HEAD, GET
INFO 01-18 18:18:22 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 18:18:22 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 18:18:22 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 18:18:22 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 18:18:22 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 18:18:22 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 18:18:22 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 18:18:22 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:47414 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:50132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:18:31 metrics.py:345] Avg prompt throughput: 7.4 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:18:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 104.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:44478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44484 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44506 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44526 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44532 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44570 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44590 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44600 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44606 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44638 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44646 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44696 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44698 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44718 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44734 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44774 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44776 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44786 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44804 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44822 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44838 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44852 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44868 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44870 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44892 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44900 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44944 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44962 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:45158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:18:41 metrics.py:345] Avg prompt throughput: 674.2 tokens/s, Avg generation throughput: 233.5 tokens/s, Running: 80 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:18:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1802.9 tokens/s, Running: 71 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:18:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1713.1 tokens/s, Running: 66 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:18:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1796.2 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:19:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1634.2 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:19:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1257.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:19:12 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 18:19:12 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 18:20:28 api_server.py:528] vLLM API server version dev
INFO 01-18 18:20:28 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7f1039f91000>)
INFO 01-18 18:20:28 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/3b4b1e8d-d273-46a4-94a4-375d0095cd55 for IPC Path.
INFO 01-18 18:20:28 api_server.py:179] Started engine process with PID 1715780
INFO 01-18 18:20:48 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:20:48 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:20:48 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:20:50 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:20:50 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:20:50 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:20:50 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 18:20:51 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 18:20:51 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:20:55 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:20:56 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:20:56 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:20:57 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 18:20:57 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:20:57 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 01-18 18:20:57 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:20:57 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:20:57 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:20:57 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:20:57 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1716114)[0;0m WARNING 01-18 18:20:57 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1716112)[0;0m WARNING 01-18 18:20:57 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 18:20:57 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1716113)[0;0m WARNING 01-18 18:20:57 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 18:20:57 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7fe62ca76980>, local_subscribe_port=41209, remote_subscribe_port=None)
INFO 01-18 18:20:57 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:20:57 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:20:57 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:20:57 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:20:58 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 18:20:58 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:20:58 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:20:58 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:21:00 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:21:01 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:21:01 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:21:02 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:21:03 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 18:21:03 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
INFO 01-18 18:21:05 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 18:21:05 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:21:05 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:21:05 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:21:05 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:21:05 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:21:05 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:21:05 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1716112)[0;0m INFO 01-18 18:21:21 model_runner.py:1530] Graph capturing finished in 15 secs.
[1;36m(VllmWorkerProcess pid=1716113)[0;0m INFO 01-18 18:21:21 model_runner.py:1530] Graph capturing finished in 15 secs.
[1;36m(VllmWorkerProcess pid=1716114)[0;0m INFO 01-18 18:21:21 model_runner.py:1530] Graph capturing finished in 15 secs.
INFO 01-18 18:21:21 model_runner.py:1530] Graph capturing finished in 16 secs.
INFO 01-18 18:21:21 api_server.py:232] vLLM to use /tmp/tmptvz77j02 as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 18:21:21 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 18:21:21 launcher.py:19] Available routes are:
INFO 01-18 18:21:21 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET
INFO 01-18 18:21:21 launcher.py:27] Route: /docs, Methods: HEAD, GET
INFO 01-18 18:21:21 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 01-18 18:21:21 launcher.py:27] Route: /redoc, Methods: HEAD, GET
INFO 01-18 18:21:21 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 18:21:21 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 18:21:21 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 18:21:21 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 18:21:21 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 18:21:21 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 18:21:21 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 18:21:21 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:52018 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:46064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:21:29 metrics.py:345] Avg prompt throughput: 8.8 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:21:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 101.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60862 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60868 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60894 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60914 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60934 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32788 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32810 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33034 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33082 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33354 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33408 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33430 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33440 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33450 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33480 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33526 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33544 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33566 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33578 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33580 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33590 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:21:40 metrics.py:345] Avg prompt throughput: 737.7 tokens/s, Avg generation throughput: 159.0 tokens/s, Running: 99 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:33604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33616 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33622 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33686 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33712 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33720 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33736 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33738 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33794 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33816 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33826 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33836 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33862 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33940 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:21:45 metrics.py:345] Avg prompt throughput: 527.2 tokens/s, Avg generation throughput: 1856.0 tokens/s, Running: 156 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:21:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2143.0 tokens/s, Running: 141 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:21:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2051.2 tokens/s, Running: 133 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.
INFO 01-18 18:22:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2006.1 tokens/s, Running: 119 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:22:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2122.7 tokens/s, Running: 102 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:22:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2011.8 tokens/s, Running: 90 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:22:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1801.0 tokens/s, Running: 69 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:22:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1718.5 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:22:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1214.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:22:27 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 18:22:27 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 18:23:43 api_server.py:528] vLLM API server version dev
INFO 01-18 18:23:43 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7f2253509090>)
INFO 01-18 18:23:43 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/fe95836e-ed1f-4161-8f11-012e93ce898c for IPC Path.
INFO 01-18 18:23:43 api_server.py:179] Started engine process with PID 1717421
INFO 01-18 18:24:01 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:24:01 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:24:01 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:24:03 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:24:03 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:24:03 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:24:03 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 18:24:04 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 18:24:04 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:08 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:08 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:08 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:09 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 18:24:09 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:09 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:09 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:09 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:09 utils.py:1008] Found nccl from library libnccl.so.2
INFO 01-18 18:24:09 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:09 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1717758)[0;0m WARNING 01-18 18:24:09 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1717759)[0;0m WARNING 01-18 18:24:09 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1717757)[0;0m WARNING 01-18 18:24:09 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 18:24:09 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 18:24:09 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f43a197b490>, local_subscribe_port=51559, remote_subscribe_port=None)
INFO 01-18 18:24:09 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:09 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:09 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:09 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 01-18 18:24:10 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:10 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:10 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:10 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 18:24:12 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:13 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:14 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:14 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:24:15 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 18:24:15 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
INFO 01-18 18:24:17 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 18:24:17 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:17 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:17 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:17 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:17 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:17 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:17 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1717758)[0;0m INFO 01-18 18:24:34 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1717759)[0;0m INFO 01-18 18:24:34 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1717757)[0;0m INFO 01-18 18:24:34 model_runner.py:1530] Graph capturing finished in 16 secs.
INFO 01-18 18:24:34 model_runner.py:1530] Graph capturing finished in 16 secs.
INFO 01-18 18:24:34 api_server.py:232] vLLM to use /tmp/tmpl7s2utc6 as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 18:24:34 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 18:24:34 launcher.py:19] Available routes are:
INFO 01-18 18:24:34 launcher.py:27] Route: /openapi.json, Methods: GET, HEAD
INFO 01-18 18:24:34 launcher.py:27] Route: /docs, Methods: GET, HEAD
INFO 01-18 18:24:34 launcher.py:27] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 01-18 18:24:34 launcher.py:27] Route: /redoc, Methods: GET, HEAD
INFO 01-18 18:24:34 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 18:24:34 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 18:24:34 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 18:24:34 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 18:24:34 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 18:24:34 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 18:24:34 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 18:24:34 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:53858 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:42874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:24:43 metrics.py:345] Avg prompt throughput: 8.3 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:24:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 104.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48864 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48944 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48956 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49190 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49206 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49324 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49378 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49398 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49430 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49432 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49444 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49450 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49456 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49566 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49574 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49586 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49590 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49612 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49626 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49692 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49704 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49708 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49720 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49738 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49792 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49814 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49830 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49838 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:24:53 metrics.py:345] Avg prompt throughput: 840.2 tokens/s, Avg generation throughput: 178.9 tokens/s, Running: 109 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:49844 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49892 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49894 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49912 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49924 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49956 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49946 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49964 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50012 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50108 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50276 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50314 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50352 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50354 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50370 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50398 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50416 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50428 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50436 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50464 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50500 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50532 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50548 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50580 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50630 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50654 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50658 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50678 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50686 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50702 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50816 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50828 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50878 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50900 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50912 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50956 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51108 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51120 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51228 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51340 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51352 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51368 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51374 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51416 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51420 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51422 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51428 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51440 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51456 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51508 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51546 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51556 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51588 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51664 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51684 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51700 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51704 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51712 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51734 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:24:58 metrics.py:345] Avg prompt throughput: 638.5 tokens/s, Avg generation throughput: 1855.1 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 62 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:03 metrics.py:345] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 2231.7 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 51 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:08 metrics.py:345] Avg prompt throughput: 31.8 tokens/s, Avg generation throughput: 2283.3 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 33 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:13 metrics.py:345] Avg prompt throughput: 133.5 tokens/s, Avg generation throughput: 2241.4 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 16 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:19 metrics.py:345] Avg prompt throughput: 205.6 tokens/s, Avg generation throughput: 2229.1 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:24 metrics.py:345] Avg prompt throughput: 87.0 tokens/s, Avg generation throughput: 2302.2 tokens/s, Running: 246 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2193.8 tokens/s, Running: 230 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2287.3 tokens/s, Running: 211 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2230.5 tokens/s, Running: 199 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2217.7 tokens/s, Running: 185 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2160.4 tokens/s, Running: 165 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1924.6 tokens/s, Running: 145 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:25:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2024.7 tokens/s, Running: 113 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:26:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1960.5 tokens/s, Running: 83 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:26:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1657.1 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:26:15 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 18:26:15 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 18:27:31 api_server.py:528] vLLM API server version dev
INFO 01-18 18:27:31 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7f3aa07e5090>)
INFO 01-18 18:27:31 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/7275b8a4-6bfe-4a3d-bec0-18c34e68dc32 for IPC Path.
INFO 01-18 18:27:31 api_server.py:179] Started engine process with PID 1719363
INFO 01-18 18:27:49 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:27:49 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:27:49 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:27:52 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:27:52 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:27:52 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:27:52 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 18:27:53 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 18:27:53 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:27:57 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:27:57 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:27:57 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 18:27:57 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:27:57 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:27:57 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:27:57 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:27:57 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 01-18 18:27:57 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:27:57 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:27:57 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1719692)[0;0m WARNING 01-18 18:27:58 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1719693)[0;0m WARNING 01-18 18:27:58 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 18:27:58 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1719694)[0;0m WARNING 01-18 18:27:58 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 18:27:58 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f81f057da20>, local_subscribe_port=36813, remote_subscribe_port=None)
INFO 01-18 18:27:58 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:27:58 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:27:58 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:27:58 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 01-18 18:27:58 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:27:58 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:27:58 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:27:58 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 18:28:01 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:28:01 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:28:02 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:28:02 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:28:03 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 18:28:03 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:28:06 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:28:06 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:28:06 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:28:06 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:28:06 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:28:06 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 18:28:06 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 18:28:06 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1719693)[0;0m INFO 01-18 18:28:22 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1719692)[0;0m INFO 01-18 18:28:22 model_runner.py:1530] Graph capturing finished in 16 secs.
[1;36m(VllmWorkerProcess pid=1719694)[0;0m INFO 01-18 18:28:22 model_runner.py:1530] Graph capturing finished in 16 secs.
INFO 01-18 18:28:22 model_runner.py:1530] Graph capturing finished in 16 secs.
INFO 01-18 18:28:23 api_server.py:232] vLLM to use /tmp/tmp6zoprlty as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 18:28:23 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 18:28:23 launcher.py:19] Available routes are:
INFO 01-18 18:28:23 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET
INFO 01-18 18:28:23 launcher.py:27] Route: /docs, Methods: HEAD, GET
INFO 01-18 18:28:23 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 01-18 18:28:23 launcher.py:27] Route: /redoc, Methods: HEAD, GET
INFO 01-18 18:28:23 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 18:28:23 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 18:28:23 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 18:28:23 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 18:28:23 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 18:28:23 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 18:28:23 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 18:28:23 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:33626 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:47516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:28:31 metrics.py:345] Avg prompt throughput: 8.4 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:28:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 104.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:50710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50796 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50822 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50838 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50852 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50894 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50900 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50914 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50940 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50944 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51366 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51374 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51376 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51378 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51416 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51422 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51428 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51456 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51514 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51544 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51546 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51548 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51566 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51580 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51594 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51598 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51626 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51640 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51654 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:28:41 metrics.py:345] Avg prompt throughput: 839.4 tokens/s, Avg generation throughput: 178.2 tokens/s, Running: 110 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:51694 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51700 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51704 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51732 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51750 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51810 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51862 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51878 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51918 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51962 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51982 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52012 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52038 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52112 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52120 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52338 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52348 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52376 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52384 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52398 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52422 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52464 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52508 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52544 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52564 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52586 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52594 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52640 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52658 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52668 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52670 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52684 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52696 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52708 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52734 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52780 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52822 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52864 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52882 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52914 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52966 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52982 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53198 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53268 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53378 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53406 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53422 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53430 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53450 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53542 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53566 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53582 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53598 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53616 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53626 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53640 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53650 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53696 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53730 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53776 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53788 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53814 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53828 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53862 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53878 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53920 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54012 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54268 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54368 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54352 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54376 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54384 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54442 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54480 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54534 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54546 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54636 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54646 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54684 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54694 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54718 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54732 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54744 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54774 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54796 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54822 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54826 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54852 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54878 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54920 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55016 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55034 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35622 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:28:46 metrics.py:345] Avg prompt throughput: 633.6 tokens/s, Avg generation throughput: 1867.0 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 237 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:35660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35670 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35694 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35730 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35776 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35786 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35792 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35900 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36038 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36082 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36138 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36228 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36324 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36352 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36422 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36430 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36440 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36444 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36450 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36486 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36534 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36544 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36588 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36606 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36630 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36636 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36646 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36692 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36720 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36732 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36766 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36792 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36794 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36858 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36900 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36946 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36966 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37016 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:28:51 metrics.py:345] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 2220.5 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 371 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:28:57 metrics.py:345] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 2305.5 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 354 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:02 metrics.py:345] Avg prompt throughput: 152.4 tokens/s, Avg generation throughput: 2227.5 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 335 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:07 metrics.py:345] Avg prompt throughput: 218.3 tokens/s, Avg generation throughput: 2208.9 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 323 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:12 metrics.py:345] Avg prompt throughput: 184.0 tokens/s, Avg generation throughput: 2086.9 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 311 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:17 metrics.py:345] Avg prompt throughput: 283.1 tokens/s, Avg generation throughput: 2131.7 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 295 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:22 metrics.py:345] Avg prompt throughput: 251.9 tokens/s, Avg generation throughput: 2142.8 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 279 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:27 metrics.py:345] Avg prompt throughput: 347.1 tokens/s, Avg generation throughput: 2085.9 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 264 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:32 metrics.py:345] Avg prompt throughput: 232.8 tokens/s, Avg generation throughput: 2132.7 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 249 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:37 metrics.py:345] Avg prompt throughput: 147.9 tokens/s, Avg generation throughput: 2065.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 240 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:42 metrics.py:345] Avg prompt throughput: 207.8 tokens/s, Avg generation throughput: 2143.3 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 227 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:47 metrics.py:345] Avg prompt throughput: 299.9 tokens/s, Avg generation throughput: 2076.0 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 211 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:52 metrics.py:345] Avg prompt throughput: 437.7 tokens/s, Avg generation throughput: 1957.5 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 189 reqs, GPU KV cache usage: 22.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:29:57 metrics.py:345] Avg prompt throughput: 208.1 tokens/s, Avg generation throughput: 2071.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 165 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:02 metrics.py:345] Avg prompt throughput: 129.4 tokens/s, Avg generation throughput: 1971.4 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 147 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:08 metrics.py:345] Avg prompt throughput: 136.3 tokens/s, Avg generation throughput: 2138.9 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 128 reqs, GPU KV cache usage: 22.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:13 metrics.py:345] Avg prompt throughput: 171.0 tokens/s, Avg generation throughput: 2101.1 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 104 reqs, GPU KV cache usage: 21.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:18 metrics.py:345] Avg prompt throughput: 139.9 tokens/s, Avg generation throughput: 2138.7 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 84 reqs, GPU KV cache usage: 21.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:23 metrics.py:345] Avg prompt throughput: 124.6 tokens/s, Avg generation throughput: 2122.4 tokens/s, Running: 253 reqs, Swapped: 0 reqs, Pending: 62 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:28 metrics.py:345] Avg prompt throughput: 185.4 tokens/s, Avg generation throughput: 1920.5 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 40 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:33 metrics.py:345] Avg prompt throughput: 404.8 tokens/s, Avg generation throughput: 1927.7 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 6 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:38 metrics.py:345] Avg prompt throughput: 79.5 tokens/s, Avg generation throughput: 2231.2 tokens/s, Running: 230 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2224.9 tokens/s, Running: 200 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2185.0 tokens/s, Running: 178 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2083.2 tokens/s, Running: 145 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.
INFO 01-18 18:30:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1998.8 tokens/s, Running: 122 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:31:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1901.2 tokens/s, Running: 97 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:31:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1785.2 tokens/s, Running: 61 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:31:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1560.7 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:31:21 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 18:31:21 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 01-18 18:32:37 api_server.py:528] vLLM API server version dev
INFO 01-18 18:32:37 api_server.py:529] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7f20c1295090>)
INFO 01-18 18:32:37 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/1d21f040-d236-497c-b3e9-dbc0a95ed0ee for IPC Path.
INFO 01-18 18:32:37 api_server.py:179] Started engine process with PID 1722043
INFO 01-18 18:32:57 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:32:57 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:32:57 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:32:59 config.py:887] Defaulting to use mp for distributed inference
WARNING 01-18 18:32:59 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-18 18:32:59 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 01-18 18:32:59 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 01-18 18:33:00 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 40 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-18 18:33:00 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:04 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:04 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:04 multiproc_worker_utils.py:216] Worker ready; awaiting tasks
INFO 01-18 18:33:04 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:04 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:04 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 01-18 18:33:04 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:04 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:04 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:04 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:04 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=1722380)[0;0m WARNING 01-18 18:33:05 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1722379)[0;0m WARNING 01-18 18:33:05 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=1722381)[0;0m WARNING 01-18 18:33:05 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-18 18:33:05 custom_all_reduce.py:132] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-18 18:33:05 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f36c7c8a2c0>, local_subscribe_port=35673, remote_subscribe_port=None)
INFO 01-18 18:33:05 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:05 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:05 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:05 model_runner.py:1060] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 01-18 18:33:05 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:05 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:05 weight_utils.py:243] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:05 weight_utils.py:243] Using model weights format ['*.safetensors']
INFO 01-18 18:33:08 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:08 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:09 model_runner.py:1071] Loading model weights took 3.7710 GB
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:09 model_runner.py:1071] Loading model weights took 3.7710 GB
INFO 01-18 18:33:10 distributed_gpu_executor.py:57] # GPU blocks: 32890, # CPU blocks: 8192
INFO 01-18 18:33:10 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 4.01x
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:13 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:13 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:13 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:13 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:13 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:13 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-18 18:33:13 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-18 18:33:13 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=1722380)[0;0m INFO 01-18 18:33:30 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1722381)[0;0m INFO 01-18 18:33:30 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 18:33:30 model_runner.py:1530] Graph capturing finished in 17 secs.
[1;36m(VllmWorkerProcess pid=1722379)[0;0m INFO 01-18 18:33:30 model_runner.py:1530] Graph capturing finished in 17 secs.
INFO 01-18 18:33:31 api_server.py:232] vLLM to use /tmp/tmpcwkdree0 as PROMETHEUS_MULTIPROC_DIR
WARNING 01-18 18:33:31 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 01-18 18:33:31 launcher.py:19] Available routes are:
INFO 01-18 18:33:31 launcher.py:27] Route: /openapi.json, Methods: GET, HEAD
INFO 01-18 18:33:31 launcher.py:27] Route: /docs, Methods: GET, HEAD
INFO 01-18 18:33:31 launcher.py:27] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 01-18 18:33:31 launcher.py:27] Route: /redoc, Methods: GET, HEAD
INFO 01-18 18:33:31 launcher.py:27] Route: /health, Methods: GET
INFO 01-18 18:33:31 launcher.py:27] Route: /tokenize, Methods: POST
INFO 01-18 18:33:31 launcher.py:27] Route: /detokenize, Methods: POST
INFO 01-18 18:33:31 launcher.py:27] Route: /v1/models, Methods: GET
INFO 01-18 18:33:31 launcher.py:27] Route: /version, Methods: GET
INFO 01-18 18:33:31 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 01-18 18:33:31 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 01-18 18:33:31 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     127.0.0.1:46012 - "GET / HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:46014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:33:39 metrics.py:345] Avg prompt throughput: 8.5 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:33:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 104.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48582 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48586 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48636 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48668 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48720 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48800 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48816 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48864 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48868 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48898 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48944 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49190 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49228 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49368 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49406 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49432 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49436 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49444 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49508 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49528 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49548 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49582 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49616 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49622 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49638 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49650 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:33:49 metrics.py:345] Avg prompt throughput: 772.9 tokens/s, Avg generation throughput: 162.4 tokens/s, Running: 100 reqs, Swapped: 0 reqs, Pending: 9 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:49658 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49678 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49686 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49692 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49708 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49720 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49722 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49736 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49804 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49816 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49852 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49912 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49944 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49966 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:49998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50034 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50138 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50268 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50324 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50340 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50348 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50368 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50370 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50408 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50442 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50500 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50526 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50564 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50582 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50612 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50626 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50694 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50738 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50766 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50774 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50794 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50796 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50810 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50826 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50882 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50892 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50920 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50946 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50966 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51276 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51314 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51340 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51360 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51368 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51376 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51378 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51410 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51428 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51450 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51462 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51484 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51500 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51506 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51562 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51600 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51658 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51668 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51696 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51708 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51712 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51732 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51788 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51796 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51812 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51826 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51864 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51890 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51894 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52082 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52314 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52360 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52430 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52464 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52526 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52586 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52612 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52622 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52638 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52650 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52654 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52670 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52678 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52692 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52700 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52712 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52736 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52746 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52766 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52814 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52816 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52828 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52830 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52854 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52870 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52888 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52934 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52956 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52964 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53012 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53034 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:33:54 metrics.py:345] Avg prompt throughput: 736.2 tokens/s, Avg generation throughput: 1781.8 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 219 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:53038 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53112 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53206 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53276 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53352 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53366 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53384 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53406 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53420 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53436 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53506 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53522 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53532 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53542 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53556 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53588 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53610 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53626 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53630 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53646 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53650 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53678 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53694 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53718 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53730 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53736 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53758 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53764 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53776 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53788 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53806 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53828 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53892 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53906 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53912 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53920 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53944 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54138 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34532 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34548 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34564 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34578 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34586 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34590 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34602 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34612 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34644 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34654 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34682 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34698 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34712 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34714 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34728 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34730 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34784 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34786 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34806 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34812 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34826 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34828 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34836 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34862 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34874 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34908 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34924 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34962 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35016 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35120 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35198 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35366 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35376 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35420 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35576 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35586 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35652 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35666 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35686 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35702 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35714 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35722 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35738 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35814 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35820 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35848 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35866 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35886 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35894 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35904 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35914 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35946 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35956 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35964 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:35998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36338 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36354 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36370 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36374 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:33:59 metrics.py:345] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 2167.8 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 553 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:36400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36406 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36440 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36452 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36462 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36488 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36508 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36528 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36546 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36556 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36564 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36578 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36582 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36594 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36600 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36614 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36618 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36636 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36664 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36698 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36714 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36720 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36732 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36752 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36766 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36794 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36822 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36832 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36854 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36864 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36894 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36910 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37034 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37324 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37354 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37368 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37378 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37396 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37416 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37428 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37432 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37442 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37462 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37480 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37488 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37534 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37548 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37556 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37560 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37562 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37592 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37606 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37624 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37634 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37648 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37662 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37686 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37690 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37702 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37712 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37722 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37730 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37748 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37750 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37770 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37772 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37778 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37790 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37810 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37814 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37840 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37842 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37856 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37896 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37898 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37900 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37918 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37930 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37956 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38012 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38050 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38366 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38376 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38416 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38432 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38444 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38452 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38488 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38522 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38546 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38570 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38584 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38590 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38596 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38598 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38608 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38638 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38642 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38656 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38664 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38674 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38688 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38704 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38712 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38716 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38724 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38736 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38742 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38756 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38762 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38768 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38782 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38798 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38814 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38824 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38830 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38834 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38846 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38850 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38860 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38872 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38876 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38880 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38884 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38898 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38902 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38912 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38920 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38924 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38934 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38946 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39024 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39050 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39082 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39108 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39112 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39190 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39348 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39398 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39410 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39416 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39428 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39444 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39458 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39500 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39528 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39568 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39572 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39588 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39604 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39620 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39628 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39630 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:34:04 metrics.py:345] Avg prompt throughput: 33.1 tokens/s, Avg generation throughput: 2268.6 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 895 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:39640 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39654 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39660 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39672 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39684 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39696 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39704 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39710 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39726 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39740 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39738 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39754 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39766 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39774 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39780 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39796 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39802 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39808 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39818 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 01-18 18:34:09 metrics.py:345] Avg prompt throughput: 153.4 tokens/s, Avg generation throughput: 2191.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 895 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:14 metrics.py:345] Avg prompt throughput: 144.8 tokens/s, Avg generation throughput: 2245.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 885 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:19 metrics.py:345] Avg prompt throughput: 301.9 tokens/s, Avg generation throughput: 2121.7 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 870 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:24 metrics.py:345] Avg prompt throughput: 231.1 tokens/s, Avg generation throughput: 1976.4 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 857 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:29 metrics.py:345] Avg prompt throughput: 274.3 tokens/s, Avg generation throughput: 2095.2 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 841 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:35 metrics.py:345] Avg prompt throughput: 284.3 tokens/s, Avg generation throughput: 2062.1 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 826 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:40 metrics.py:345] Avg prompt throughput: 159.5 tokens/s, Avg generation throughput: 2182.4 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 816 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:45 metrics.py:345] Avg prompt throughput: 219.1 tokens/s, Avg generation throughput: 1977.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 803 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:50 metrics.py:345] Avg prompt throughput: 188.1 tokens/s, Avg generation throughput: 2128.8 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 791 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:34:55 metrics.py:345] Avg prompt throughput: 357.3 tokens/s, Avg generation throughput: 2006.4 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 772 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:00 metrics.py:345] Avg prompt throughput: 381.8 tokens/s, Avg generation throughput: 1985.6 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 753 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:05 metrics.py:345] Avg prompt throughput: 226.6 tokens/s, Avg generation throughput: 2053.6 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 733 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:10 metrics.py:345] Avg prompt throughput: 147.7 tokens/s, Avg generation throughput: 1922.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 711 reqs, GPU KV cache usage: 21.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:15 metrics.py:345] Avg prompt throughput: 164.9 tokens/s, Avg generation throughput: 2107.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 690 reqs, GPU KV cache usage: 22.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:20 metrics.py:345] Avg prompt throughput: 148.8 tokens/s, Avg generation throughput: 2080.9 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 667 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:25 metrics.py:345] Avg prompt throughput: 164.9 tokens/s, Avg generation throughput: 2093.3 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 643 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:30 metrics.py:345] Avg prompt throughput: 107.2 tokens/s, Avg generation throughput: 2163.4 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 629 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:36 metrics.py:345] Avg prompt throughput: 194.4 tokens/s, Avg generation throughput: 2063.8 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 601 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:41 metrics.py:345] Avg prompt throughput: 310.1 tokens/s, Avg generation throughput: 1772.0 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 569 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:46 metrics.py:345] Avg prompt throughput: 362.3 tokens/s, Avg generation throughput: 1963.1 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 545 reqs, GPU KV cache usage: 18.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:51 metrics.py:345] Avg prompt throughput: 456.0 tokens/s, Avg generation throughput: 1883.2 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 513 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:35:56 metrics.py:345] Avg prompt throughput: 215.8 tokens/s, Avg generation throughput: 2103.3 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 494 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:01 metrics.py:345] Avg prompt throughput: 237.3 tokens/s, Avg generation throughput: 2114.0 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 478 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:06 metrics.py:345] Avg prompt throughput: 503.1 tokens/s, Avg generation throughput: 1718.9 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 455 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:11 metrics.py:345] Avg prompt throughput: 165.3 tokens/s, Avg generation throughput: 2114.4 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 433 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:16 metrics.py:345] Avg prompt throughput: 193.9 tokens/s, Avg generation throughput: 2101.6 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 413 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:21 metrics.py:345] Avg prompt throughput: 147.2 tokens/s, Avg generation throughput: 2166.3 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 400 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:26 metrics.py:345] Avg prompt throughput: 103.4 tokens/s, Avg generation throughput: 2126.4 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 381 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:31 metrics.py:345] Avg prompt throughput: 161.6 tokens/s, Avg generation throughput: 1908.7 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 361 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:36 metrics.py:345] Avg prompt throughput: 185.3 tokens/s, Avg generation throughput: 2059.2 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 333 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:41 metrics.py:345] Avg prompt throughput: 150.2 tokens/s, Avg generation throughput: 2115.8 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 312 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:47 metrics.py:345] Avg prompt throughput: 185.1 tokens/s, Avg generation throughput: 2093.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 294 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:52 metrics.py:345] Avg prompt throughput: 381.3 tokens/s, Avg generation throughput: 1974.8 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 278 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:36:57 metrics.py:345] Avg prompt throughput: 497.1 tokens/s, Avg generation throughput: 1724.2 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 260 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:02 metrics.py:345] Avg prompt throughput: 510.5 tokens/s, Avg generation throughput: 1884.0 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 244 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:07 metrics.py:345] Avg prompt throughput: 371.5 tokens/s, Avg generation throughput: 1975.6 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 224 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:12 metrics.py:345] Avg prompt throughput: 556.6 tokens/s, Avg generation throughput: 1819.1 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 200 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:17 metrics.py:345] Avg prompt throughput: 683.3 tokens/s, Avg generation throughput: 1774.7 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 180 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:22 metrics.py:345] Avg prompt throughput: 293.5 tokens/s, Avg generation throughput: 1789.3 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 156 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:27 metrics.py:345] Avg prompt throughput: 232.4 tokens/s, Avg generation throughput: 2068.6 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 140 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:32 metrics.py:345] Avg prompt throughput: 69.6 tokens/s, Avg generation throughput: 2128.0 tokens/s, Running: 256 reqs, Swapped: 0 reqs, Pending: 113 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:37 metrics.py:345] Avg prompt throughput: 54.7 tokens/s, Avg generation throughput: 2161.6 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 94 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:42 metrics.py:345] Avg prompt throughput: 58.4 tokens/s, Avg generation throughput: 2169.3 tokens/s, Running: 254 reqs, Swapped: 0 reqs, Pending: 75 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:47 metrics.py:345] Avg prompt throughput: 46.1 tokens/s, Avg generation throughput: 1989.2 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 60 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:52 metrics.py:345] Avg prompt throughput: 112.9 tokens/s, Avg generation throughput: 2105.0 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 32 reqs, GPU KV cache usage: 18.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:37:57 metrics.py:345] Avg prompt throughput: 132.1 tokens/s, Avg generation throughput: 2067.4 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:02 metrics.py:345] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 2246.0 tokens/s, Running: 231 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2238.5 tokens/s, Running: 208 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2181.5 tokens/s, Running: 185 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1977.7 tokens/s, Running: 161 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2027.1 tokens/s, Running: 133 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2016.8 tokens/s, Running: 99 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1807.8 tokens/s, Running: 68 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1570.2 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 723.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 01-18 18:38:47 multiproc_worker_utils.py:134] Terminating local vLLM worker processes
INFO 01-18 18:38:47 launcher.py:57] Shutting down FastAPI HTTP server.
